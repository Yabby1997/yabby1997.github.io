---
layout: post
title: "🧑‍💻 모각코 9주차"
description: "2020년 겨울방학, 모여서 각자 코딩하자!"
date: 2020-02-14
feature_image: images/thumbnail_mogakko_9.png
tags: [모각코, CNU, Tensorflow, Keras, Python]
---

이전 글 [🧑‍💻 모각코 8주차](https://yabby1997.github.io/mogakko_8) 보러가기.

# 👀 오늘의 할 일
- 🧑‍💻 MNIST Classification 실습

# 🧑‍💻 MNIST Classification 실습
특강 실습에서 Fashion MNIST를 이용한 Classification은 직접 실습했으나, 전통적인 MNIST에 대한 실습은 하지 않았었다. 오늘은 가볍게 Fashion MNIST 실습을 참고하여 MNIST Classification을 구현해보려고 한다. 

## Import
텐서플로우 2.0, keras, numpy, matplotlib, collections를 사용한다.
```python
try:
  # Colab only
  %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt
import collections as col
```
colab은 기본적으로 tensorflow 1버전을 사용한다. 위의 코드는 2버전을 사용하도록 강제한다. colab에서만 사용이 가능하다. 

## Dataset 가져오기
keras에서는 MNIST 데이터를 기본적으로 제공한다. 아래 코드를 통해 훈련셋과 테스트셋을 손쉽게 가져올 수 있다.
```python
mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

print(train_images.shape)
print(train_labels.shape)
print(test_images.shape)
print(test_labels.shape)
```
{% include image_caption.html imageurl="/images/mogakko_9_1.png" title="" caption="수행결과" %}

## Label 별 개수 확인
collections의 Counter함수를 통해 label별로 몇개씩 있는지 확인할 수 있다. Fashion MNIST와는 달리 고르게 분포되어있지 않다. 보기좋게 matplotlib의 histogram을 통해 시각화 해 보았다. 
```python
col.Counter(train_labels)
col.Counter(test_labels)
plt.hist(train_labels, color = 'green', alpha = .5)
plt.hist(test_labels, color = 'green', alpha = .5)
```
{% include image_caption.html imageurl="/images/mogakko_9_2.png" title="" caption="수행결과" %}
{% include image_caption.html imageurl="/images/mogakko_9_3.png" title="" caption="수행결과" %}

## 이미지 확인
훈련 이미지 셋에서 첫번째 이미지를 시각화하여 확인해보았다.
```python
plt.figure(figsize = (10, 10))        # 전체 피겨 사이즈를 10*10으로
for i in range(25) :
  plt.subplot(5, 5, i + 1)
  plt.xticks([])                      # x 눈금 제거
  plt.yticks([])                      # y 눈금 제거
  plt.xlabel(train_labels[i])         # x 축 라벨에 정답
  plt.imshow(train_images[i])
```
{% include image_caption.html imageurl="/images/mogakko_9_4.png" title="" caption="수행결과" %}

## 이미지 분석, 정규화
이미지는 255까지의 강도를 갖는 픽셀 24*24개로 이루어 져 있다. 따라서 255로 나눠줌으로 써 이미지의 모든 픽셀을 0~1사이의 수로 표현할 수 있다. (정규화) 255로 나눈 뒤, Counter와 figure를 통해 정규화가 되었음을 확인할 수 있다. 
```python
col.Counter(train_images[0].reshape(784))    # 0 번째 이미지(24*24 2차원 배열)를 784사이즈의 1차원 배열로 reshape하여 요소(색을 결정하는 수치)를 확인해 보았다.
```
{% include image_caption.html imageurl="/images/mogakko_9_5.png" title="" caption="수행결과" %}
0~255의 값을 갖는걸 확인할 수 있다.
```python
train_images = train_images / 255.0
test_images = test_images / 255.0

col.Counter(train_images[0].reshape(784))
```
{% include image_caption.html imageurl="/images/mogakko_9_6.png" title="" caption="수행결과" %}
255.0으로 나누어 0~1.0사이의 값을 갖게된것을 확인할 수 있다.
```python
plt.figure(figsize = (10, 10))
plt.imshow(train_images[0])
plt.colorbar()
plt.show()
```
{% include image_caption.html imageurl="/images/mogakko_9_7.png" title="" caption="수행결과" %}
`figure()`를 통해 그림을 그려보아서도 확인이 가능하다. 
## 학습 모델
keras를 이용하면 간단하게 모델을 만들어낼 수 있다.
cost함수로 sparse categorical crossentropy를 사용한다. crossentropy는 단순히 맞았냐 틀리냐로만 cost를 계산하는게 아니라 얼마의 차이로 인해 틀렸는지 까지 계산에 포함한다. 따라서 분류문제에서 더 나은 cost를 계산해낸다. 관련 내용은 [여기](http://funmv2013.blogspot.com/2017/01/cross-entropy.html)에서 참조했다. crossentropy중에서도 [sparse를 사용하는 이유](https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other)는 [one-hot encoding](https://wikidocs.net/22647)되어있는 자료가 아니기 때문이다. Optimizer는 [Adam optimizer](http://mjgim.me/2018/01/22/adam.html)를 사용한다. 대부분의 경우에서 가장 잘 작동하는 Optimizer로, Optimizer의 끝판왕(..)이라는 말도 있다. 사실 아직 깊게 공부해보지 않아서 무슨 차이가 있는지는 모른다. 차후에 공부해야겠다.
```python
model = keras.Sequential()
model.add(keras.layers.Flatten(input_shape = (28, 28)))
model.add(keras.layers.Dense(128, activation = 'relu'))
model.add(keras.layers.Dense(10, activation = 'softmax'))

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=10)
```
{% include image_caption.html imageurl="/images/mogakko_9_8.png" title="" caption="수행결과" %}
훈련 셋에 대해서 99%까지의 정확도가 나올 정도로 학습이 된 것을 확인할 수 있다.
## 검증
학습결과를 검증. `model.evaluate()`를 통해서 학습된 모델을 검증할 수 있다.
```python
loss, accuracy = model.evaluate(test_images,  test_labels, verbose = 1)
print('\ntest loss\t: ', loss)
print('test accuracy\t: ', accuracy)
```
{% include image_caption.html imageurl="/images/mogakko_9_9.png" title="" caption="수행결과" %}
테스트 셋에 대해서는 정확도가 97%가량이 나옴을 확인할 수 있다. 아무레도 훈련 셋에 대한 overfitting이 약간 있는것으로 추정된다. 
```python
predictions = model.predict(test_images)
plt.figure(figsize=(20,20))
for i in range(25) :
  plt.subplot(5, 5, i+1)
  plt.imshow(test_images[i])
  plt.xticks([])
  plt.yticks([])
  description = str(np.argmax(predictions[i])) + " / " + str(test_labels[i])
  plt.xlabel(description)
plt.show()
```
{% include image_caption.html imageurl="/images/mogakko_9_10.png" title="" caption="수행결과" %}
테스트 셋 초기 25개의 이미지에 대해 이미지와 예측값, 정답을 함께 보여주도록 출력해보았다. 


이전에 Fashion MNIST를 통해 실습해본 경험으로 인해 이번 실습은 어렵지않게 진행할 수 있었다. 또 저번에 도전했던 Bank marketing dataset 실습과 달리 이번 MNIST classification에서는 오직 Keras를 사용해 모델을 만들었는데, 그 과정이 매우 간단하고 직관적이어서 이제는 정말 딥러닝이 많이 대중화가 되었음을 느꼈다. 
